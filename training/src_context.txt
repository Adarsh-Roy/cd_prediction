<file path="__init__.py">

</file>

<file path="main.py">
"""
Main command-line entry-point for the Cd-prediction project.

Run from the project root, e.g.

    python -m src.main train \
        --config experiments/exp_name/config.json \
        --resume experiments/exp_name/checkpoints/best_model_val_mae=-0.012.pt
"""

from __future__ import annotations

import argparse
import sys
from pathlib import Path

import numpy as np

from src.config.constants import (
    DEFAULT_NUM_SLICES,
    DEFAULT_SLICE_AXIS,
    DEFAULT_TARGET_POINTS,
    POINT_CLOUDS_DIR,
    PREPARED_DATASET_DIR,
    PREPARED_DATASET_PADDED_DIR,
    SLICE_DIR,
    SUBSET_DIR,
    model_to_padded,
)
from src.data.dataset import CdDataset
from src.data.slices import PointCloudSlicer, display_slices, prepare_dataset
from src.evaluation.evaluate import run_evaluation
from src.inference.predict import predict
from src.training.ignite_loops import run_training
from src.utils.io import load_config
from src.utils.logger import logger


def build_parser() -> argparse.ArgumentParser:
    """Configure argparse sub-commands."""
    parser = argparse.ArgumentParser(
        description="Cd-prediction: slicing · training · evaluation · inference"
    )

    subparsers = parser.add_subparsers(dest="command", required=True)

    # --------------------------------------------------------------------- #
    # slice                                                                 #
    # --------------------------------------------------------------------- #
    slice_p = subparsers.add_parser("slice", help="Slice 3-D point clouds")
    slice_p.add_argument("--input-dir", type=Path, default=POINT_CLOUDS_DIR)
    slice_p.add_argument("--output-dir", type=Path, default=SLICE_DIR)
    slice_p.add_argument("--num-slices", type=int, default=DEFAULT_NUM_SLICES)
    slice_p.add_argument("--axis", choices=["x", "y", "z"], default=DEFAULT_SLICE_AXIS)
    slice_p.add_argument("--max-files", type=int)
    slice_p.add_argument(
        "--split", choices=["train", "val", "test", "all"], default="all"
    )
    slice_p.add_argument("--subset-dir", type=Path, default=SUBSET_DIR)

    # --------------------------------------------------------------------- #
    # visualize                                                             #
    # --------------------------------------------------------------------- #
    viz_p = subparsers.add_parser("visualize", help="Show saved 2-D slices")
    viz_p.add_argument(
        "-i", "--input", type=Path, required=True, help="Path to .npy slice file"
    )
    viz_p.add_argument("--cols", type=int, default=5)
    viz_p.add_argument("--limit", type=int)
    viz_p.add_argument("--axis", choices=["x", "y", "z"], default=DEFAULT_SLICE_AXIS)
    viz_p.add_argument("--save-path")

    # --------------------------------------------------------------------- #
    # prep                                                                  #
    # --------------------------------------------------------------------- #
    prep_p = subparsers.add_parser("prep", help="Prepare Dataset")
    prep_p.add_argument(
        "-s", "--split", choices=["train", "val", "test", "all"], default="all"
    )
    prep_p.add_argument("--slice-dir", type=Path, default=SLICE_DIR)
    prep_p.add_argument("--output-dir", type=Path, default=PREPARED_DATASET_DIR)
    prep_p.add_argument(
        "--pad",
        action="store_true",
        help="If set, the slices are padded and masked. Use the flag --target-points to specify the number of points per slice.",
    )
    prep_p.add_argument("--target-points", type=int, default=DEFAULT_TARGET_POINTS)
    prep_p.add_argument("--subset-dir", type=Path, default=SUBSET_DIR)

    # --------------------------------------------------------------------- #
    # fit scaler                                                            #
    # --------------------------------------------------------------------- #
    fit_scaler_p = subparsers.add_parser("fit_scaler", help="Fit Scaler")
    fit_scaler_p.add_argument("--prepared-dataset-dir", type=Path)
    fit_scaler_p.add_argument(
        "--config",
        type=Path,
        required=True,
        help="Path to YAML / JSON experiment config",
    )
    fit_scaler_p.add_argument(
        "--padded",
        action="store_true",
        help="Only used when --prepared-dataset-dir is not provided."
        "If set, use the default padded dataset directory, otherwise, use the default non-padded dataset",
    )

    # --------------------------------------------------------------------- #
    # train                                                                 #
    # --------------------------------------------------------------------- #
    train_p = subparsers.add_parser("train", help="Train a model")
    train_p.add_argument(
        "--config",
        type=Path,
        required=True,
        help="Path to YAML / JSON experiment config",
    )
    train_p.add_argument(
        "--resume",
        type=Path,
        help="Full path to checkpoint to resume from.  "
        "If omitted, you will be prompted interactively.",
    )
    train_p.add_argument(
        "--exp-name",
        type=str,
        required=True,
        help="Name for this experiment run (e.g. lr1e-3_bs32).",
    )
    train_p.add_argument("--prepared-dataset-dir", type=Path)
    train_p.add_argument(
        "--fit-scaler",
        action="store_true",
        help="If set, fit a scaler to the training data. Otherwise, use the already"
        "available scaler.",
    )

    # --------------------------------------------------------------------- #
    # Evaluate                                                              #
    # --------------------------------------------------------------------- #
    eval_p = subparsers.add_parser("evaluate", help="Evaluate a checkpoint")
    eval_p.add_argument(
        "--config", type=Path, required=True, help="Experiment config YAML / JSON"
    )
    eval_p.add_argument(
        "--checkpoint", type=Path, required=True, help="Path to model *.pt file"
    )
    eval_p.add_argument("--split", choices=["val", "test"], default="test")
    eval_p.add_argument(
        "--prepared-dataset-dir", type=Path, default=PREPARED_DATASET_DIR
    )

    # --------------------------------------------------------------------- #
    # Predict                                                               #
    # --------------------------------------------------------------------- #
    # --------------------------------------------------------------------- #
    # Predict                                                               #
    # --------------------------------------------------------------------- #
    pred_p = subparsers.add_parser("predict", help="Run single-file inference")
    pred_p.add_argument(
        "--config", type=Path, required=True, help="Experiment config YAML / JSON"
    )
    pred_p.add_argument(
        "--checkpoint", type=Path, required=True, help="Model *.pt checkpoint"
    )
    pred_p.add_argument(
        "--point-cloud",
        type=Path,
        required=True,
        help="Path to the *.paddle_tensor point-cloud file",
    )

    return parser


# --------------------------------------------------------------------------- #
# Entrypoint dispatcher                                                       #
# --------------------------------------------------------------------------- #
def main() -> None:
    parser = build_parser()
    args = parser.parse_args()

    # ------------------------------ slice --------------------------------- #
    if args.command == "slice":
        slicer = PointCloudSlicer(
            input_dir=args.input_dir,
            output_dir=args.output_dir,
            num_slices=args.num_slices,
            axis=args.axis,
            max_files=args.max_files,
            split=args.split,
            subset_dir=args.subset_dir,
        )
        slicer.run()

    # ---------------------------- visualize ------------------------------- #
    elif args.command == "visualize":
        if not args.input.is_file():
            parser.error(f"File not found: {args.input}")
        slices = np.load(args.input, allow_pickle=True)
        car_id = args.input.stem
        display_slices(
            slices,
            design_id=car_id,
            n_cols=args.cols,
            limit=args.limit,
            axis=args.axis,
            save_path=args.save_path,
        )

    # ------------------------------- pad ---------------------------------- #
    elif args.command == "prep":
        if args.pad:
            target_points = args.target_points
        else:
            target_points = None

        prepare_dataset(
            slice_dir=args.slice_dir,
            output_dir=args.output_dir,
            split=args.split,
            target_points=target_points,
            subset_dir=args.subset_dir,
        )

    elif args.command == "fit_scaler":
        dataset_path: Path | None = args.prepared_dataset_dir
        cfg = load_config(args.config)
        padded: bool = cfg["data"]["padded"]
        debugging: bool = cfg["debugging"]
        if dataset_path is None:
            if padded:
                dataset_path = PREPARED_DATASET_PADDED_DIR
            else:
                dataset_path = PREPARED_DATASET_DIR
        _ = CdDataset(
            root_dir=dataset_path,
            split="train",
            padded=padded,
            debugging=debugging,
            fit_scaler=True,
        )

    # ------------------------------ train --------------------------------- #
    elif args.command == "train":
        resume: Path | None = args.resume
        if resume:
            if not Path(resume).is_file():
                logger.error(f"Checkpoint not found: {resume}")
                sys.exit(1)
        dataset_path: Path | None = args.prepared_dataset_dir
        if dataset_path is None:
            cfg = load_config(args.config)
            padded: bool = model_to_padded[cfg["model"]["model_type"]]
            if padded:
                dataset_path = PREPARED_DATASET_PADDED_DIR
            else:
                dataset_path = PREPARED_DATASET_DIR

        run_training(
            exp_name=args.exp_name,
            cfg_path=args.config,
            resume=resume,
            preapred_dataset_dir=dataset_path,
            fit_scaler=args.fit_scaler,
        )

    # ---------------------------- evaluate -------------------------------- #
    elif args.command == "evaluate":
        dataset_path: Path | None = args.prepared_dataset_dir
        if dataset_path is None:
            cfg = load_config(args.config)
            padded: bool = model_to_padded[cfg["model"]["model_type"]]
            if padded:
                dataset_path = PREPARED_DATASET_PADDED_DIR
            else:
                dataset_path = PREPARED_DATASET_DIR
        run_evaluation(
            cfg_path=args.config,
            checkpoint_path=args.checkpoint,
            split=args.split,
            preapred_dataset_dir=dataset_path,
        )

    # ----------------------------- predict -------------------------------- #
    elif args.command == "predict":
        cd_val = predict(
            cfg_path=args.config,
            checkpoint_path=args.checkpoint,
            point_cloud_path=args.point_cloud,
        )
        print(f"Predicted Cd  →  {cd_val:.5f}")


if __name__ == "__main__":
    main()

</file>

<file path="config/constants.py">
from pathlib import Path

# ------------------------------------------------------------------ #
#  Project roots                                                     #
# ------------------------------------------------------------------ #
PROJECT_ROOT = Path(__file__).resolve().parents[2]  # …/Cd_prediction/C_d
DATA_DIR = PROJECT_ROOT / "data"
RAW_DIR = DATA_DIR / "raw"
PROC_DIR = DATA_DIR / "processed"
EXP_DIR = PROJECT_ROOT / "experiments"

# ------------------------------------------------------------------ #
#  Raw / processed paths                                             #
# ------------------------------------------------------------------ #
POINT_CLOUDS_DIR = RAW_DIR / "PointClouds"
SUBSET_DIR = RAW_DIR / "subset_dir"

SLICE_DIR = PROC_DIR / "slices"
PREPARED_DATASET_DIR = PROC_DIR / "prepared_dataset"
PREPARED_DATASET_PADDED_DIR = PROC_DIR / "prepared_dataset" / "padded"
SCALER_FILE = PROC_DIR / "scalers" / "scaler.pkl"  # <— single file
# TODO: [LATER] support exp-name based scaler files when we have different datasets


# ------------------------------------------------------------------ #
#  Cd table                                                          #
# ------------------------------------------------------------------ #
# Master CSV produced by the CFD post-processing workflow
DRAG_CSV = RAW_DIR / "cleaned_drag_coefficients.csv"

# ------------------------------------------------------------------ #
#  Pre-processing defaults                                           #
# ------------------------------------------------------------------ #
DEFAULT_NUM_SLICES = 80
DEFAULT_SLICE_AXIS = "x"
DEFAULT_TARGET_POINTS = 6_500


# ------------------------------------------------------------------ #
#  Model to Padding mapping                                          #
# ------------------------------------------------------------------ #
model_to_padded: dict[str, bool] = {"plm": True, "dlm": False}

</file>

<file path="training/ignite_loops.py">
"""
Training loop for Cd prediction.

Run from project root, e.g.:

    python -m src.main train \
        --config experiments/configuration.json \
        --resume experiments/checkpoints/best_model_val_loss=0.0123.pt

The file expects:
*   A CD dataset (`src.data.dataset.CdDataset`)
*   A model
*   Project-wide paths in `src.config.constants`
"""

from __future__ import annotations

import sys
from pathlib import Path

import torch
import torch.nn as nn
from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer
from ignite.handlers import (
    Checkpoint,
    DiskSaver,
    EarlyStopping,
    ModelCheckpoint,
    TensorboardLogger,
    global_step_from_engine,
)
from ignite.handlers.tqdm_logger import ProgressBar
from ignite.metrics import MeanAbsoluteError, MeanSquaredError
from ignite.metrics.regression.r2_score import R2Score
from torch.utils.data import DataLoader
from tqdm.contrib.logging import logging_redirect_tqdm

from src.config.constants import EXP_DIR, PREPARED_DATASET_DIR, model_to_padded
from src.data.dataset import (
    CdDataset,
    ragged_collate_fn,
)
from src.models.model import get_model
from src.utils.helpers import make_unscale, prepare_device, prepare_ragged_batch_fn
from src.utils.io import load_config
from src.utils.logger import logger


# --------------------------------------------------------------------------- #
# Public API                                                                  #
# --------------------------------------------------------------------------- #
def run_training(
    exp_name: str,
    cfg_path: str | Path,
    resume: Path | None = None,
    preapred_dataset_dir: Path = PREPARED_DATASET_DIR,
    fit_scaler: bool = False,
):
    """
    Main entry-point called from CLI to run training.
    The training config is loaded from `cfg_path`.
    The training is resumed if checkpoint path `resume` if provided.

    Args:
        exp_name: name of this experiment (used to create sub-directories for
        checkpoints and tb-logs)
        cfg_path: path to YAML / JSON describing the experiment.
        resume:   optional checkpoint to resume (full state: model, optimiser, trainer).
        preapred_dataset_dir: path to the directory with the prepared dataset.
    """
    cfg = load_config(cfg_path)

    # --------------------------------------------------------------------- #
    # Reproducibility & device                                              #
    # --------------------------------------------------------------------- #
    seed = cfg.get("seed", 42)
    debugging = cfg.get("debugging", False)
    batch_size = cfg["data"].get("batch_size", 4)
    torch.manual_seed(seed)
    device = prepare_device(cfg.get("device"))

    # --------------------------------------------------------------------- #
    # Data                                                                  #
    # --------------------------------------------------------------------- #
    padded: bool = model_to_padded[cfg["model"]["model_type"]]
    train_set = CdDataset(
        root_dir=preapred_dataset_dir,
        split="train",
        fit_scaler=fit_scaler,
        padded=padded,
        debugging=debugging,
    )
    val_set = CdDataset(
        root_dir=preapred_dataset_dir,
        split="val",
        fit_scaler=False,
        padded=padded,
        debugging=debugging,
    )
    scaler = train_set.scaler
    unscale_fn = make_unscale(scaler=scaler)

    # --------------------------------------------------------------------- #
    # Model, optimiser, criterion                                           #
    # --------------------------------------------------------------------- #
    model_type = cfg["model"]["model_type"]
    model = get_model(model_type=model_type, **cfg["model"][model_type]).to(device)
    optim_params = cfg.get("optim", {}).get("params", {"lr": 1e-3})
    optimizer = torch.optim.Adam(model.parameters(), **optim_params)
    criterion = nn.MSELoss()

    if padded:
        train_loader = DataLoader(
            train_set,
            batch_size=batch_size,
            pin_memory=(device.type == "cuda"),
            shuffle=True,
            drop_last=True,
        )
        val_loader = DataLoader(
            val_set,
            batch_size=batch_size,
            pin_memory=(device.type == "cuda"),
            shuffle=False,
            drop_last=False,
        )
        trainer = create_supervised_trainer(model, optimizer, criterion, device=device)
        train_evaluator = create_supervised_evaluator(
            model,
            metrics={
                "mae": MeanAbsoluteError(),
                "mse": MeanSquaredError(),
                "r2": R2Score(),
            },
            output_transform=unscale_fn,
            device=device,
        )
        val_evaluator = create_supervised_evaluator(
            model,
            metrics={
                "mae": MeanAbsoluteError(),
                "mse": MeanSquaredError(),
                "r2": R2Score(),
            },
            output_transform=unscale_fn,
            device=device,
        )
    else:
        train_loader = DataLoader(
            train_set,
            shuffle=True,
            drop_last=True,
            batch_size=batch_size,
            pin_memory=(device.type == "cuda"),
            collate_fn=ragged_collate_fn,
        )
        val_loader = DataLoader(
            val_set,
            shuffle=False,
            drop_last=False,
            batch_size=batch_size,
            pin_memory=(device.type == "cuda"),
            collate_fn=ragged_collate_fn,
        )
        trainer = create_supervised_trainer(
            model,
            optimizer,
            criterion,
            device=device,
            prepare_batch=prepare_ragged_batch_fn,
        )
        train_evaluator = create_supervised_evaluator(
            model,
            metrics={
                "mae": MeanAbsoluteError(),
                "mse": MeanSquaredError(),
                "r2": R2Score(),
            },
            output_transform=unscale_fn,
            prepare_batch=prepare_ragged_batch_fn,
            device=device,
        )
        val_evaluator = create_supervised_evaluator(
            model,
            metrics={
                "mae": MeanAbsoluteError(),
                "mse": MeanSquaredError(),
                "r2": R2Score(),
            },
            output_transform=unscale_fn,
            device=device,
            prepare_batch=prepare_ragged_batch_fn,
        )

    # --------------------------------------------------------------------- #
    # Logging and Monitoring                                                #
    # --------------------------------------------------------------------- #
    train_pbar = ProgressBar(desc="Training", persist=True)
    train_pbar.attach(trainer, output_transform=lambda loss: {"batch_loss": loss})

    train_eval_pbar = ProgressBar(desc="Training Set Evaluation", persist=True)
    train_eval_pbar.attach(train_evaluator)
    val_eval_pbar = ProgressBar(desc="Validation Set Evaluation", persist=True)
    val_eval_pbar.attach(val_evaluator)

    # Log running loss every N iterations
    log_interval = cfg["training"].get("log_interval", 100)

    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))
    def _log_iter(engine):
        train_pbar.log_message(
            f"\n\nEpoch[{engine.state.epoch}] "
            f"Iter[{engine.state.iteration}] "
            f"bach_loss={engine.state.output:.4f}\n\n"  # scaled batch loss for this iteration
        )

    tb_logger = TensorboardLogger(log_dir=EXP_DIR / exp_name / "tb-logs")

    # Log the scaled loss that we are using for criterion calculation during training.
    tb_logger.attach_output_handler(
        trainer,
        event_name=Events.ITERATION_COMPLETED(every=log_interval),
        tag="training",
        output_transform=lambda loss: {"batch_loss": loss},
    )

    @trainer.on(Events.EPOCH_COMPLETED)
    def _eval_and_log(engine):
        train_evaluator.run(train_loader)
        train_metrics = train_evaluator.state.metrics
        val_evaluator.run(val_loader)
        val_metrics = val_evaluator.state.metrics
        train_pbar.log_message(
            f"\n\nEpoch {engine.state.epoch}: "
            f"train MAE={train_metrics['mae']:.4f} | "
            f"train R2={train_metrics['r2']:.4f} | "
            f"val MAE={val_metrics['mae']:.4f} | "
            f"val R2={val_metrics['r2']:.4f}\n\n"
        )

        step = engine.state.epoch

        tb_logger.writer.add_scalars(
            "MAE",
            {"train": train_metrics["mae"], "validation": val_metrics["mae"]},
            step,
        )

        tb_logger.writer.add_scalars(
            "MSE",
            {"train": train_metrics["mse"], "validation": val_metrics["mse"]},
            step,
        )

        tb_logger.writer.add_scalars(
            "R2", {"train": train_metrics["r2"], "validation": val_metrics["r2"]}, step
        )

    def score_fn(eng):
        """
        Score function needed for early stopping and checkpointing.
        Should be used with Val Evaluator's engine.
        Returns the negative of mae.
        """
        return -eng.state.metrics["mae"]  # minimise MAE

    # --------------------------------------------------------------------- #
    # Early stopping                                                        #
    # --------------------------------------------------------------------- #
    early_stop_handler = EarlyStopping(
        patience=cfg["training"].get("early_stop_patience", 10),
        score_function=score_fn,
        trainer=trainer,
        min_delta=cfg["training"].get("early_stop_min_delta", 0.0),
        cumulative_delta=False,
    )
    val_evaluator.add_event_handler(Events.COMPLETED, early_stop_handler)

    # --------------------------------------------------------------------- #
    # Checkpointing                                                         #
    # --------------------------------------------------------------------- #

    # save the best models based on val_evaluator's mae
    # (meant for inference, not resuming training)
    best_model_saver = ModelCheckpoint(
        dirname=EXP_DIR / exp_name / "model_checkpoints",
        filename_prefix="best_",
        n_saved=3,
        global_step_transform=global_step_from_engine(trainer),
        score_function=score_fn,
        score_name="val_mae",
        require_empty=False,
    )
    val_evaluator.add_event_handler(
        Events.COMPLETED, best_model_saver, {"model": model}
    )

    # save the entire training state after every epoch of trainer
    # (meant for resuming)
    to_save = {"trainer": trainer, "model": model, "optimizer": optimizer}
    training_state_saver = Checkpoint(
        to_save=to_save,
        save_handler=DiskSaver(
            EXP_DIR / exp_name / "training_state_checkpoints",
            create_dir=True,
            atomic=True,
            require_empty=False,
        ),
        filename_prefix="training_state_",
        global_step_transform=global_step_from_engine(trainer),
        n_saved=5,
    )
    trainer.add_event_handler(Events.EPOCH_COMPLETED, training_state_saver)

    # Resume full state if requested
    if resume:
        ckpt_fp = Path(resume)
        if not ckpt_fp.exists():
            logger.error(f"Resume checkpoint not found: {ckpt_fp}")
            sys.exit(1)
        logger.info(f"Resuming from checkpoint: {ckpt_fp}")
        to_load = {"model": model, "optimizer": optimizer, "trainer": trainer}
        Checkpoint.load_objects(
            to_load=to_load, checkpoint=torch.load(ckpt_fp, map_location=device)
        )
        # Override the learning-rate(s) if a value is provided in the config
        cfg_lr = cfg.get("optim", {}).get("params", {}).get("lr")
        if cfg_lr is not None:
            for i, param_group in enumerate(optimizer.param_groups):
                old_lr = param_group.get("lr", None)
                if old_lr is not None and old_lr != cfg_lr:
                    logger.info(
                        f"Param-group {i}: overriding LR {old_lr:.3e} → {cfg_lr:.3e}"
                    )
                param_group["lr"] = cfg_lr

    # --------------------------------------------------------------------- #
    # Start training                                                        #
    # --------------------------------------------------------------------- #
    with logging_redirect_tqdm():
        trainer.run(train_loader, max_epochs=cfg["training"]["epochs"])
    tb_logger.close()

</file>

<file path="training/__init__.py">

</file>

<file path="utils/io.py">
"""
Utility method for input/output from the disk.
"""

from __future__ import annotations

import json
from pathlib import Path
from typing import TYPE_CHECKING

import joblib
import paddle
import pandas as pd
import yaml

from src.config.constants import DRAG_CSV, SCALER_FILE, SUBSET_DIR
from src.utils.logger import logger

if TYPE_CHECKING:
    import numpy as np
    from sklearn.preprocessing import StandardScaler


def load_point_cloud(file_path: Path) -> np.ndarray:
    """
    Args:
        file_path: Path to the .paddle_tensor file.
    Returns:
        A numpy array of shape (N, 3) where N is the number of points in the point cloud.
    """
    tensor = paddle.load(str(file_path))
    return tensor.numpy()


def load_design_ids(split: str, subset_dir: Path = SUBSET_DIR) -> set[str]:
    """
    Load the design IDs for a given split from the subset directory.

    Args:
        split: The data split to load the design IDs for.
        subset_dir: Path to the directory with the design IDs for the split. (.txt files)
    Returns:
        A set of design ID strings.
    """
    split_file = split_file = Path(subset_dir) / f"{split}_design_ids.txt"
    if not split_file.is_file():
        raise FileNotFoundError(f"Split file not found: {split_file}")
    with open(split_file) as f:
        ids = {line.strip() for line in f if line.strip()}
    logger.info(f"Loaded {len(ids)} design IDs for split: {split}")
    return ids


def save_scaler(scaler, path: Path = SCALER_FILE) -> Path:
    """
    Persist a fitted sklearn-style scaler (e.g. StandardScaler) to disk.

    Args:
        scaler: any object with sklearn's fit/transform attributes (has mean_, scale_, etc.).
        path: path to the scaler file

    Returns:
        The full path where the scaler was written.
    """
    path.parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(scaler, path)
    logger.info(f"Saved scaler to {path}")
    return path


def load_scaler(path: Path = SCALER_FILE) -> StandardScaler:
    """
    Load a previously saved scaler from disk.

    Args:
        path: path to the scaler file

    Returns:
        The deserialized scaler object (e.g. a StandardScaler with mean_/scale_ populated).

    Raises:
        FileNotFoundError if the file does not exist.
    """
    if not path.is_file():
        raise FileNotFoundError(f"No scaler found at: {path}")
    scaler = joblib.load(path)
    logger.info(f"Loaded scaler from {path}")
    return scaler


def load_cd_map(csv_path: Path = DRAG_CSV) -> dict[str, float]:
    """
    Load the drag-coefficient CSV and return a dict that maps design IDs to C_d.

    Args:
        csv_path: Path to the CSV file.
    Returns:
        A dict of the form `{design_id: Cd}`.
    """
    if not csv_path.is_file():
        raise FileNotFoundError(csv_path)
    df = pd.read_csv(csv_path, usecols=["Design", "Average Cd"])
    cd_map = dict(zip(df["Design"], df["Average Cd"]))
    logger.info(f"Loaded Cd table with {len(cd_map)} entries from {csv_path}")
    return cd_map


def load_config(cfg_path: str | Path) -> dict:
    """Load a YAML or JSON experiment-config file."""
    cfg_path = Path(cfg_path)
    if not cfg_path.exists():
        raise FileNotFoundError(cfg_path)
    if cfg_path.suffix in {".yml", ".yaml"}:
        with cfg_path.open() as f:
            cfg = yaml.safe_load(f)
    elif cfg_path.suffix == ".json":
        with cfg_path.open() as f:
            cfg = json.load(f)
    else:
        raise ValueError(f"Unsupported config type: {cfg_path.suffix}")
    logger.info(f"Loaded config from {cfg_path}")
    return cfg

</file>

<file path="utils/__init__.py">

</file>

<file path="utils/logger.py">
"""
Logging configuration and common logger object.
"""

import logging

logging.basicConfig(
    level=logging.DEBUG, format="%(asctime)s [%(levelname)s] %(message)s"
)

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

</file>

<file path="utils/model_summary_script.py">
"""
Print a detailed summary and size for the Cd-DLM model
------------------------------------------------------
$ python print_model_stats.py --config default_config.json --device cuda:0
$ python print_model_stats.py --device cpu                           # uses default config
"""

from __future__ import annotations

import argparse
import io
from collections import defaultdict
from pathlib import Path
from types import SimpleNamespace

import torch

# — project imports —
from src.models.model import get_model
from src.utils.io import load_config


# ------------------------------------------------------------------- #
# helpers                                                             #
# ------------------------------------------------------------------- #
def count_parameters(model: torch.nn.Module) -> SimpleNamespace:
    """
    Returns:
        total         : int
        trainable     : int
        per_component : dict[str, int]
    """
    total = trainable = 0
    per_component: dict[str, int] = defaultdict(int)

    for name, p in model.named_parameters():
        n = p.numel()
        total += n
        if p.requires_grad:
            trainable += n
        # e.g. "slice_encoder.conv1.weight"  ->  "slice_encoder"
        top = name.split(".")[0]
        per_component[top] += n
    return SimpleNamespace(
        total=total, trainable=trainable, per_component=dict(per_component)
    )


def estimate_state_dict_size_mb(model: torch.nn.Module) -> float:
    """
    Serialises state_dict to an in-memory buffer and returns its size (MiB).
    """
    buffer = io.BytesIO()
    torch.save(
        model.state_dict(), buffer
    )  # ← identical to saving to disk :contentReference[oaicite:0]{index=0}
    return buffer.getbuffer().nbytes / 1_048_576


# ------------------------------------------------------------------- #
# main                                                                #
# ------------------------------------------------------------------- #
def main(config: Path | str, device: str):
    # -------- config + model -------- #
    cfg = load_config(config)
    model_type = cfg["model"]["model_type"]
    model_params = cfg["model"][model_type]
    model = get_model(model_type="dlm", **model_params).to(device)

    # -------- parameter stats -------- #
    stats = count_parameters(
        model
    )  # Keras-style breakdown :contentReference[oaicite:1]{index=1}

    print("=" * 60)
    print(model)  # native PyTorch repr
    print("-" * 60)

    print(f"Total parameters     : {stats.total:,}")
    print(f"Trainable parameters : {stats.trainable:,}\n")

    print("Parameters by component")
    for comp, n in stats.per_component.items():
        print(f"  • {comp:<18}: {n:,}")

    # -------- size on disk -------- #
    size_mb = estimate_state_dict_size_mb(model)  # uses torch.save() buffer
    print(f"\nApprox. state_dict size: {size_mb:.2f} MiB")

    # -------- optional rich summary -------- #
    try:
        from torchinfo import (
            summary,
        )  # GitHub: TylerYep/torchinfo :contentReference[oaicite:2]{index=2}

        dummy_input = model.example_input(  # synthetic PyG batches accepted by summary
            batch_size=2, S=model.num_slices
        )  # torch_geometric Batch API :contentReference[oaicite:3]{index=3}

        summary(
            model,
            input_data=dummy_input,  # torchinfo handles list / tuple inputs :contentReference[oaicite:4]{index=4}
            depth=3,
            col_names=("input_size", "output_size", "num_params"),
        )
    except ImportError:
        print(
            "\n[torchinfo not found]  Install with `pip install torchinfo` "
            "for a detailed layer-by-layer table."
        )


# ------------------------------------------------------------------- #
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--config",
        type=Path,
        default=None,
        help="Path to a JSON/YAML config (defaults to load_config() behaviour)",
    )
    parser.add_argument(
        "--device",
        default="cpu",
        help="cuda:0 | cpu | mps | ...",
    )
    main(**vars(parser.parse_args()))

</file>

<file path="utils/helpers.py">
import torch
from sklearn.preprocessing import StandardScaler


def prepare_device(device_str: str | None = None) -> torch.device:
    if device_str:
        return torch.device(device_str)
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")


def prepare_ragged_batch_fn(batch, device, non_blocking):
    slice_batches, cd_values = batch
    # move each PyG Batch
    slice_batches = [sb.to(device) for sb in slice_batches]
    # move targets
    cd_values = cd_values.to(device, non_blocking=non_blocking)
    return slice_batches, cd_values


def make_unscale(scaler: StandardScaler):
    def _unscale(x, y, y_pred):
        """
        This is used to unscale the output from the model before passing it on for
        metrics calculation. Ignite passes `(y_pred, y)` in the `output` argument.

        Args:
            output: A tuple of (y_pred, y)

        Returns:
            A tuple of unscaled prediction and real values. That is, (y_pred_u, y_u)
        """

        y_pred_u = (
            torch.from_numpy(
                scaler.inverse_transform(y_pred.detach().cpu().reshape(-1, 1))
            )
            .to(y_pred.device)
            .view_as(y_pred)
        )
        y_u = (
            torch.from_numpy(scaler.inverse_transform(y.detach().cpu().reshape(-1, 1)))
            .to(y.device)
            .view_as(y)
        )
        return y_pred_u, y_u

    return _unscale

</file>

<file path="models/__init__.py">
# TODO: [LATER] Tidy up all components and models to get rid of slice mask nad max number of slices if present anywhere.
# TODO: Add dropout properly.

</file>

<file path="models/model.py">
from src.config.constants import DEFAULT_NUM_SLICES
from src.models.experiment_models.model_PLM import Cd_PLM_Model


def get_model(
    model_type: str = "plm",
    slice_input_dim: int = 2,
    slice_emb_dim: int = 256,
    design_emb_dim: int = 512,
    lstm_hidden_dim: int = 256,
    k_neighbors: int = 16,
    num_slices: int = DEFAULT_NUM_SLICES,
):
    """
    Return an instantiated Cd model based on model_type.

    - "plm" → PointNet + LSTM + MLP
    - "dlm" → DGCNN + LSTM + MLP
    - "ptm" → PointNet + Transformer + MLP [LATER]
    - "dtm" → DGCNN + Transformer + MLP (uses dynamic slice batching) [LATER]

    Returns:
        nn.Module
    """
    if model_type == "plm":
        return Cd_PLM_Model(
            slice_input_dim=slice_input_dim,
            slice_emb_dim=slice_emb_dim,
            lstm_hidden_dim=lstm_hidden_dim,
            design_emb_dim=design_emb_dim,
        )
    elif model_type == "dlm":
        raise NotImplementedError("DLM is not implemented yet.")

    elif model_type == "ptm":
        raise NotImplementedError("PTM is not implemented yet.")

    elif model_type == "dtm":
        raise NotImplementedError("DTM is not implement yet.")

    else:
        raise ValueError(f"Unsupported model_type '{model_type}'. use 'plm'.")

</file>

<file path="models/experiment_models/model_DTM.py">
import torch
import torch.nn as nn
from torch_geometric.data import Batch

from src.models.components.dgcnn import EdgeConvSliceEncoder
from src.models.components.transformer_encoder import TransformerSliceEncoder
from src.models.components.mlp_head import CdRegressor


class Cd_DTM_Model(nn.Module):
    """
    Dynamic Graph CNN + Transformer + MLP model.
    Accepts a list of 80 PyG Batches (one per slice index across batch).
    """

    def __init__(
        self,
        slice_input_dim: int = 2,
        slice_emb_dim: int = 256,
        transformer_hidden_dim: int = 256,
        transformer_layers: int = 2,
        transformer_heads: int = 1,
        transformer_dropout: float = 0.1,
        max_num_slices: int = 80,
        k_neighbors: int = 20,
    ):
        super().__init__()

        self.slice_encoder = EdgeConvSliceEncoder(
            input_dim=slice_input_dim,
            emb_dim=slice_emb_dim,
            k=k_neighbors,
        )

        self.temporal_encoder = TransformerSliceEncoder(
            input_dim=slice_emb_dim,
            hidden_dim=transformer_hidden_dim,
            num_layers=transformer_layers,
            nhead=transformer_heads,
            dropout=transformer_dropout,
            max_seq_len=max_num_slices,
        )

        self.head = CdRegressor(input_dim=slice_emb_dim)

    def forward(self, car_slice_batches: list[Batch]) -> torch.Tensor:
        """
        Args:
            car_slice_batches (list of PyG Batch objects):
                Length = S (num slices). Each is a PyG Batch with:
                - x:      (N_points, 2)
                - batch:  (N_points,) → batch sample index

        Returns:
            Tensor: (B,) Cd prediction per sample
        """
        device = next(self.parameters()).device
        slice_embeddings = []

        for slice_batch in car_slice_batches:
            slice_batch = slice_batch.to(device)
            emb = self.slice_encoder(slice_batch)  # (B, emb_dim)
            slice_embeddings.append(emb)

        # Stack to (S, B, emb_dim) → then transpose to (B, S, emb_dim)
        transformer_input = torch.stack(slice_embeddings, dim=0).transpose(0, 1)

        car_emb = self.temporal_encoder(transformer_input)  # (B, emb_dim)
        return self.head(car_emb)  # (B,)

    @staticmethod
    def example_input(batch_size: int = 2, S: int = 80, P: int = 6500) -> list[Batch]:
        """
        Returns dummy input: list of S PyG batches, each containing B slices of shape (P, 2)
        """
        from torch_geometric.data import Data, Batch

        slice_batches = []

        for s in range(S):
            slice_data = []
            for b in range(batch_size):
                pts = torch.randn(P, 2)
                slice_data.append(Data(x=pts))
            slice_batches.append(Batch.from_data_list(slice_data))

        return slice_batches

</file>

<file path="models/experiment_models/model_PTM.py">
import torch
import torch.nn as nn

from src.models.components.pointnet_2d import PointNet2D
from src.models.components.transformer_encoder import TransformerSliceEncoder
from src.models.components.mlp_head import CdRegressor


class Cd_PTM_Model(nn.Module):
    """
    Full pipeline model:
    - Slice-wise point encoding via PointNet2D
    - Temporal encoding via Transformer
    - Regression head for Cd prediction
    """

    def __init__(
        self,
        slice_input_dim: int = 2,
        slice_emb_dim: int = 256,
        transformer_hidden_dim: int = 256,
        transformer_layers: int = 2,
        transformer_heads: int = 1,
        transformer_dropout: float = 0.1,
        encoder_emb_dim: int = 256,
        max_num_slices: int = 80,
    ):
        super().__init__()

        self.slice_encoder = PointNet2D(
            input_dim=slice_input_dim, emb_dim=slice_emb_dim
        )

        self.temporal_encoder = TransformerSliceEncoder(
            input_dim=slice_emb_dim,
            hidden_dim=transformer_hidden_dim,
            num_layers=transformer_layers,
            nhead=transformer_heads,
            dropout=transformer_dropout,
            max_seq_len=max_num_slices,
        )

        self.head = CdRegressor(input_dim=encoder_emb_dim)

    def forward(
        self, x: tuple[torch.Tensor, torch.Tensor, torch.Tensor]
    ) -> torch.Tensor:
        """
        Args:
            x: tuple of (slices, point_mask, slice_mask)
                - slices:     (B, S, P, 2)
                - point_mask: (B, S, P)
                - slice_mask: (B, S)

        Returns:
            Cd predictions: (B,) – one scalar per batch item
        """
        slices, point_mask, slice_mask = x
        B, S, P, D = slices.shape

        # Flatten slices for PointNet
        flat_pts = slices.view(B * S, P, D)  # (B·S, P, 2)
        flat_mask = point_mask.view(B * S, P)  # (B·S, P)

        # Encode each slice
        slice_embeds = self.slice_encoder(flat_pts, flat_mask)  # (B·S, emb_dim)
        slice_embeds = slice_embeds.view(B, S, -1)  # (B, S, emb_dim)

        # Zero out padded slices before transformer
        slice_embeds = slice_embeds * slice_mask.unsqueeze(-1)  # (B, S, emb_dim)

        # Temporal encoding via Transformer
        global_embedding = self.temporal_encoder(
            slice_embeds, slice_mask
        )  # (B, emb_dim)

        # Final Cd regression
        return self.head(global_embedding)  # (B,)

    @staticmethod
    def example_input(batch_size: int = 2, S: int = 80, P: int = 6500) -> tuple:
        """
        Returns a dummy batch for tracing or export.
        """
        slices = torch.randn(batch_size, S, P, 2)
        point_mask = torch.ones(batch_size, S, P)
        slice_mask = torch.ones(batch_size, S)
        return slices, point_mask, slice_mask

</file>

<file path="models/experiment_models/model_PLM.py">
import torch
import torch.nn as nn

from src.models.components.pointnet_2d import PointNet2D
from src.models.components.lstm_encoder import LSTMEncoder
from src.models.components.mlp_head import CdRegressor


class Cd_PLM_Model(nn.Module):
    """
    Full pipeline model:
    - Slice-wise point encoding via PointNet2D
    - Temporal encoding via LSTM
    - Regression head for Cd prediction
    """

    def __init__(
        self,
        slice_input_dim: int = 2,
        slice_emb_dim: int = 256,
        lstm_hidden_dim: int = 256,
        design_emb_dim: int = 512,
    ):
        super().__init__()

        self.slice_encoder = PointNet2D(
            input_dim=slice_input_dim, emb_dim=slice_emb_dim
        )

        self.temporal_encoder = LSTMEncoder(
            input_dim=slice_emb_dim, hidden_dim=lstm_hidden_dim
        )

        self.head = CdRegressor(input_dim=design_emb_dim)

    def forward(self, x: tuple[torch.Tensor, torch.Tensor]) -> torch.Tensor:
        """
        Args:
            x: tuple of (slices, point_mask)
                - slices:     (batch_size, num_slices, points_per_slice, 2)
                - point_mask: (batch_size, num_slices, points_per_slice)

        Returns:
            Cd predictions: (batch_size,) – one scaler per batch item
        """
        slices, point_mask = x
        batch_size, num_slices, points_per_slice, dim = slices.shape

        # Flatten slices for PointNet
        flat_pts = slices.view(
            batch_size * num_slices, points_per_slice, dim
        )  # (B·S, P, 2)
        flat_mask = point_mask.view(
            batch_size * num_slices, points_per_slice
        )  # (B·S, P)

        # Encode each slice
        slice_embs = self.slice_encoder(flat_pts, flat_mask)  # (B·S, emb_dim)
        slice_embs = slice_embs.view(batch_size, num_slices, -1)  # (B, S, emb_dim)

        # Temporal encoding via LSTM
        design_emb = self.temporal_encoder(slice_embs)  # (B, emb_dim)

        # Final Cd regression
        return self.head(design_emb)  # (B,)

    @staticmethod
    def example_input(batch_size: int = 2, S: int = 80, P: int = 6500) -> tuple:
        """
        Returns a dummy batch for tracing or export.
        """
        slices = torch.randn(batch_size, S, P, 2)
        point_mask = torch.ones(batch_size, S, P)
        return slices, point_mask

</file>

<file path="models/experiment_models/model_DLM.py">
"""model_DLM.py
================
Composite model that combines:

* **DGCNN slice encoder** – encodes every 2‑D slice (variable #points) into an embedding.
* **LSTM temporal encoder** – processes the ordered slice embeddings of a car design.
* **MLP regression head** – maps global design embedding to scalar drag‑coefficient (C_d).

Assumptions
-----------
* All designs share the **same, fixed number of slices** (`num_slices`).
* Each slice can contain a **variable** number of points (handled by PyG + DGCNN).
* DataLoader supplies a *list* of length `num_slices`, where each element is a
  :class:`torch_geometric.data.Batch` that stacks that particular slice across the
  mini‑batch.  See ``src.data.dataset.ragged_collate_fn`` for the reference collate.

Example
-------
>>> model = Cd_DLM_Model()
>>> slice_batches, cd_target = next(iter(loader))  # ragged_collate_fn output
>>> cd_hat = model(slice_batches)
>>> loss = criterion(cd_hat, cd_target)
"""

from __future__ import annotations

from typing import List

import torch
import torch.nn as nn
from torch_geometric.data import Batch

from src.config.constants import DEFAULT_NUM_SLICES
from src.models.components.dgcnn import EdgeConvSliceEncoder
from src.models.components.lstm_encoder import LSTMEncoder
from src.models.components.mlp_head import CdRegressor


class Cd_DLM_Model(nn.Module):
    """DGCNN + LSTM + MLP end‑to‑end C_d regressor."""

    def __init__(
        self,
        *,
        slice_input_dim: int = 2,
        slice_emb_dim: int = 256,
        k_neighbors: int = 16,
        num_slices: int = DEFAULT_NUM_SLICES,
        lstm_hidden_dim: int = 256,
    ) -> None:
        super().__init__()

        # 1️⃣ Slice‑level encoder (variable points ➜ fixed embedding)
        self.slice_encoder = EdgeConvSliceEncoder(
            input_dim=slice_input_dim,
            emb_dim=slice_emb_dim,
            k=k_neighbors,
        )

        # 2️⃣ Temporal encoder over ordered slice sequence
        self.temporal_encoder = LSTMEncoder(
            input_dim=slice_emb_dim,
            hidden_dim=lstm_hidden_dim,
        )

        # 3️⃣ Regression head – maps design embedding ➜ scalar Cd
        self.head = CdRegressor(
            input_dim=lstm_hidden_dim * 2  # LSTMEncoder is bidirectional
        )

        self.num_slices = num_slices

    # --------------------------------------------------------------------- #
    #  Forward                                                              #
    # --------------------------------------------------------------------- #
    def forward(self, slice_batches: List[Batch]) -> torch.Tensor:
        """Predict C_d for a mini‑batch.

        Parameters
        ----------
        slice_batches
            List of length *S = ``self.num_slices``*.  Each element is a
            :class:`torch_geometric.data.Batch` whose graphs correspond to the
            same slice index across the mini‑batch designs.

        Returns
        -------
        torch.Tensor
            Shape *(B,)* – predicted drag coefficient for each design.
        """

        if len(slice_batches) != self.num_slices:
            raise ValueError(
                f"Expected {self.num_slices} slice Batches but got {len(slice_batches)}."
            )

        device = next(self.parameters()).device

        # Encode every slice independently --------------------------------- #
        slice_embeddings = []
        for sb in slice_batches:
            emb = self.slice_encoder(sb.to(device))  # (B, slice_emb_dim)
            slice_embeddings.append(emb)

        # Stack → (B, S, F) ------------------------------------------------- #
        slice_seq = torch.stack(slice_embeddings, dim=1)  # (B, S, F)

        # Temporal encoding ------------------------------------------------- #
        global_emb = self.temporal_encoder(slice_seq)  # (B, 2*hidden_dim)

        # Regression -------------------------------------------------------- #
        cd_pred = self.head(global_emb)  # (B,)

        return cd_pred

    @staticmethod
    def example_input(batch_size: int = 2, S: int = 80, P: int = 6500) -> list[Batch]:
        """
        Returns dummy input: list of S PyG batches, each containing B slices of shape (P, 2)
        """
        from torch_geometric.data import Batch, Data

        slice_batches = []

        for s in range(S):
            slice_data = []
            for b in range(batch_size):
                pts = torch.randn(P, 2)
                slice_data.append(Data(x=pts))
            slice_batches.append(Batch.from_data_list(slice_data))

        return slice_batches

</file>

<file path="models/components/transformer_encoder.py">
import math
import torch
import torch.nn as nn


def generate_sinusoidal_position_embeddings(
    max_seq_len: int, embedding_dim: int
) -> torch.Tensor:
    """
    Creates sinusoidal positional encodings of shape (1, max_seq_len, embedding_dim),
    compatible with Transformer input.
    """
    pe = torch.zeros(max_seq_len, embedding_dim)
    position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)
    div_term = torch.exp(
        torch.arange(0, embedding_dim, 2).float() * (-math.log(10000.0) / embedding_dim)
    )
    pe[:, 0::2] = torch.sin(position * div_term)
    pe[:, 1::2] = torch.cos(position * div_term)
    return pe.unsqueeze(0)  # shape: (1, max_seq_len, embedding_dim)


class TransformerSliceEncoder(nn.Module):
    """
    Transformer encoder with sinusoidal positional encoding and attention pooling.
    """

    def __init__(
        self,
        input_dim: int = 256,
        hidden_dim: int = 256,
        num_layers: int = 2,
        nhead: int = 1,
        dropout: float = 0.1,
        max_seq_len: int = 80,
    ):
        """
        Args:
            input_dim: Dimension of input features per slice.
            hidden_dim: Internal feedforward dimension.
            num_layers: Number of transformer encoder layers.
            nhead: Number of attention heads.
            dropout: Dropout probability.
            max_seq_len: Maximum number of slices expected (default 80).
        """
        super().__init__()

        # Fixed sinusoidal positional embeddings
        self.register_buffer(
            "pos_encoder",
            generate_sinusoidal_position_embeddings(max_seq_len, input_dim),
        )

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=input_dim,
            nhead=nhead,
            dim_feedforward=hidden_dim * 2,
            dropout=dropout,
            batch_first=True,
            activation="relu",
        )

        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.attn_pool = nn.Linear(input_dim, 1)
        self.dropout = nn.Dropout(dropout)

    def forward(
        self, x: torch.Tensor, slice_mask: torch.Tensor | None = None
    ) -> torch.Tensor:
        """
        Args:
            x: (B, S, D) - Input sequence of slice embeddings.
            slice_mask: (B, S) - 1 for real slices, 0 for padding. Optional.

        Returns:
            (B, D) - Global embedding per sequence.
        """
        B, S, D = x.shape
        x = x + self.pos_encoder[:, :S, :]

        # Build src_key_padding_mask if slice_mask is provided
        if slice_mask is not None:
            src_key_padding_mask = slice_mask == 0  # True for pad
        else:
            src_key_padding_mask = None

        out = self.transformer(
            x, src_key_padding_mask=src_key_padding_mask
        )  # (B, S, D)

        # Attention pooling
        scores = self.attn_pool(out).squeeze(-1)  # (B, S)
        if src_key_padding_mask is not None:
            scores = scores.masked_fill(src_key_padding_mask, -1e9)

        attn_weights = torch.softmax(scores, dim=-1)  # (B, S)
        pooled = torch.sum(attn_weights.unsqueeze(-1) * out, dim=1)  # (B, D)

        return self.dropout(pooled)

</file>

<file path="models/components/lstm_encoder.py">
import torch
import torch.nn as nn


class LSTMEncoder(nn.Module):
    """Bidirectional LSTM over the (padded) slice sequence."""

    def __init__(self, input_dim: int = 256, hidden_dim: int = 256):
        """
        Args:
            input_dim: Dimension of input features per slice.
            hidden_dim: Internal feedforward dimension.
        """
        super().__init__()
        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=1,
            batch_first=True,
            bidirectional=True,
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args
            x: (batch_size, num_slices, `self.input_dim`)

        Returns
            (batch_size, 2·hidden_dim) — concatenated [fwd, bwd] last hidden states.
        """
        _, (h_n, _) = self.lstm(x)  # h_n: (2, batch_size, hidden_dim)
        h_fwd, h_bwd = h_n[-2], h_n[-1]  # (batch_size, hidden_dim) each
        return torch.cat([h_fwd, h_bwd], dim=-1)

</file>

<file path="models/components/mlp_head.py">
import torch
import torch.nn as nn


class CdRegressor(nn.Module):
    """
    Regression MLP that maps a global embedding vector to a scalar Cd value.
    """

    def __init__(self, input_dim: int = 256):
        """
        Args:
            input_dim: Dimension of the input embedding
        Output:
            Tensor of shape (B,) – scalar Cd values per input
        """
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x: (B, input_dim) – global embedding vector from encoder

        Returns:
            Cd prediction: (B,) – one scalar per sample
        """
        return self.net(x).squeeze(1)

</file>

<file path="models/components/pointnet_2d.py">
import torch
import torch.nn as nn


class PointNet2D(nn.Module):
    """
    PointNet2D with attention pooling instead of max pooling.
    Input shape: (B, N, 2)
    Mask shape: (B, N) with 1s for valid points and 0s for padded.
    Output shape: (B, emb_dim)
    """

    def __init__(self, input_dim: int = 2, emb_dim: int = 256):
        super(PointNet2D, self).__init__()

        self.mlp = nn.Sequential(
            nn.Conv1d(input_dim, 64, 1),
            nn.LeakyReLU(),
            nn.Conv1d(64, 128, 1),
            nn.LeakyReLU(),
            nn.Conv1d(128, emb_dim, 1),
            nn.LeakyReLU(),
        )

        self.attn = nn.Conv1d(emb_dim, 1, 1)  # Attention layer: (B, 1, N)

    def forward(
        self, x: torch.Tensor, mask: torch.Tensor | None = None
    ) -> torch.Tensor:
        """
        Args:
            x: (B, N, 2)         - Input points
            mask: (B, N) or None - Mask of valid points (1=real, 0=padded)

        Returns:
            (B, emb_dim) slice embedding
        """
        x = x.transpose(1, 2)  # (B, 2, N)
        features = self.mlp(x)  # (B, emb_dim, N)
        attn_logits = self.attn(features)  # (B, 1, N)

        if mask is not None:
            mask = mask.unsqueeze(1)  # (B, 1, N)
            attn_logits = attn_logits.masked_fill(mask == 0, float("-inf"))

        attn_weights = torch.softmax(attn_logits, dim=2)  # (B, 1, N)
        embedding = torch.sum(features * attn_weights, dim=2)  # (B, emb_dim)

        return embedding

</file>

<file path="models/components/dgcnn.py">
import torch
import torch.nn as nn
from torch_geometric.nn import EdgeConv, knn_graph, global_max_pool
from torch_geometric.data import Batch


class EdgeConvSliceEncoder(nn.Module):
    """
    DGCNN-style encoder for a batch of 2D point slices.

    Each slice is encoded into a fixed-size embedding vector using:
    - k-NN graph construction
    - EdgeConv over each slice
    - Global max pooling over points per slice
    """

    def __init__(self, input_dim: int = 2, emb_dim: int = 256, k: int = 20):
        """
        Args:
            input_dim (int): Dimension of input points (default: 2)
            emb_dim (int): Output embedding size for each slice
            k (int): Number of nearest neighbors for graph construction
        """
        super().__init__()
        self.k = k

        self.edge_conv = EdgeConv(
            nn=nn.Sequential(
                nn.Linear(2 * input_dim, 64),
                nn.ReLU(),
                nn.Linear(64, 128),
                nn.ReLU(),
                nn.Linear(128, emb_dim),
            ),
            aggr="max",
        )

    def forward(self, data: Batch) -> torch.Tensor:
        """
        Args:
            data (torch_geometric.data.Batch): A PyG batch containing:
                - x:      (N_total, input_dim) all points from all slices
                - batch:  (N_total,) index of which slice each point belongs to

        Returns:
            Tensor: (num_slices, emb_dim) — One embedding per slice
        """
        # Build the slice-wise k-NN graph (no inter-slice edges)
        edge_index = knn_graph(x=data.x, k=self.k, batch=data.batch)

        # Run EdgeConv over each point
        point_features = self.edge_conv(data.x, edge_index)

        # Global max pool to get a per-slice embedding
        slice_embedding = global_max_pool(point_features, data.batch)

        return slice_embedding

</file>

<file path="inference/predict.py">
"""
Single-file inference for Cd prediction.

Example
-------
python -m src.main predict \
    --config experiments/baseline.yaml \
    --checkpoint experiments/exp_name/checkpoints/best_model.pt \
    --point-cloud data/car_0001.paddle_tensor
"""

from __future__ import annotations

from pathlib import Path
from typing import List, Union

import numpy as np
import torch
from torch_geometric.data import Batch, Data

# ── project imports ──────────────────────────────────────────────────── #
from src.config.constants import (  # constants & mapping
    DEFAULT_NUM_SLICES,
    DEFAULT_SLICE_AXIS,
    DEFAULT_TARGET_POINTS,
    SCALER_FILE,
    SUBSET_DIR,
    model_to_padded,
)
from src.data.slices import (
    PointCloudSlicer,
    pad_and_mask_slices,  #
)
from src.models.model import get_model
from src.utils.helpers import prepare_device
from src.utils.io import load_config, load_scaler
from src.utils.logger import logger


# --------------------------------------------------------------------------- #
# Public API                                                                  #
# --------------------------------------------------------------------------- #
@torch.inference_mode()
def predict(
    *,
    cfg_path: Union[str, Path],
    checkpoint_path: Union[str, Path],
    point_cloud_path: Union[str, Path],
) -> float:
    """
    Run inference on a **single** point-cloud file and return the un-scaled Cd.

    Parameters
    ----------
    cfg_path
        Path to the YAML / JSON experiment config (used to recreate the model).
    checkpoint_path
        Path to the trained *.pt file.
    point_cloud_path
        Path to the *.paddle_tensor point-cloud to score.
    device
        Optional override for the compute device (e.g. "cuda:0").

    Returns
    -------
    float
        Predicted drag-coefficient **in the original scale**.
    """
    cfg = load_config(cfg_path)
    device = prepare_device(cfg.get("device"))
    model_type: str = cfg["model"]["model_type"]
    model_params = cfg["model"][model_type]

    # ------------------------------------------------------------------ #
    # Model & checkpoint                                                 #
    # ------------------------------------------------------------------ #
    model = get_model(model_type=model_type, **model_params).to(device)
    ckpt = torch.load(checkpoint_path, map_location=device)
    state = ckpt["model"] if isinstance(ckpt, dict) and "model" in ckpt else ckpt
    model.load_state_dict(state, strict=True)
    model.eval()
    logger.info(f"Loaded checkpoint → {checkpoint_path}")

    # ------------------------------------------------------------------ #
    # Point-cloud → 2-D slices                                           #
    # ------------------------------------------------------------------ #
    num_slices = cfg["data"].get("num_slices", DEFAULT_NUM_SLICES)
    axis = cfg["data"].get("slice_axis", DEFAULT_SLICE_AXIS)

    slicer = PointCloudSlicer(
        input_dir=Path("."),  # dummy
        output_dir=Path("."),  # dummy
        num_slices=num_slices,
        axis=axis,
        max_files=None,
        split="predict",
        subset_dir=SUBSET_DIR,
    )

    slices = slicer.process_file(Path(point_cloud_path))

    # ------------------------------------------------------------------ #
    # Build model input                                                  #
    # ------------------------------------------------------------------ #
    padded: bool = model_to_padded[model_type]
    if padded:
        target_pts = cfg["data"].get("target_points", DEFAULT_TARGET_POINTS)
        slices_padded, point_mask = pad_and_mask_slices(slices, target_pts)
        slices_t = torch.from_numpy(slices_padded).unsqueeze(0).float().to(device)
        p_mask_t = torch.from_numpy(point_mask).unsqueeze(0).float().to(device)
        model_input = (slices_t, p_mask_t)
    else:
        batches: List[Batch] = []
        for sl in slices:
            data = Data(x=torch.from_numpy(sl.astype(np.float32)))
            batches.append(Batch.from_data_list([data]).to(device))
        model_input = batches

    # ------------------------------------------------------------------ #
    # Forward pass                                                       #
    # ------------------------------------------------------------------ #
    import time

    # ----------------- Measure inference time -----------------
    start = time.perf_counter()
    pred_scaled: float = float(model(model_input).squeeze().cpu())
    end = time.perf_counter()

    inference_time = end - start
    logger.info(f"Inference time: {inference_time:.6f} seconds")
    logger.info(f"Predicted (scaled) Cd = {pred_scaled:.5f}")

    # ------------------------------------------------------------------ #
    # Inverse-transform to original units                                #
    # ------------------------------------------------------------------ #
    scaler = load_scaler(SCALER_FILE)  # uses the global scaler path
    cd_unscaled = float(scaler.inverse_transform(np.array([[pred_scaled]]))[0, 0])
    logger.info(f"Predicted (un-scaled) Cd = {cd_unscaled:.5f}")
    return cd_unscaled

</file>

<file path="inference/__init__.py">

</file>

<file path="evaluation/__init__.py">

</file>

<file path="evaluation/evaluate.py">
"""
Run offline evaluation of a saved Cd-Regressor checkpoint.

Example
-------
python -m src.main evaluate \
    --config experiments/baseline.yaml \
    --checkpoint experiments/exp_name/checkpoints/best_model_val_mae=0.0123.pt \
    --split test
"""

from __future__ import annotations

from pathlib import Path
from typing import Dict

import torch
from ignite.engine import create_supervised_evaluator
from ignite.handlers.tqdm_logger import ProgressBar
from ignite.metrics import MeanAbsoluteError, MeanSquaredError
from ignite.metrics.regression.r2_score import R2Score
from torch.utils.data import DataLoader

from src.config.constants import PREPARED_DATASET_DIR, model_to_padded
from src.data.dataset import CdDataset, ragged_collate_fn
from src.models.model import get_model
from src.utils.helpers import make_unscale, prepare_device, prepare_ragged_batch_fn
from src.utils.io import load_config
from src.utils.logger import logger


# --------------------------------------------------------------------------- #
# Public API                                                                  #
# --------------------------------------------------------------------------- #
def run_evaluation(
    cfg_path: str | Path,
    checkpoint_path: str | Path,
    split: str = "test",
    preapred_dataset_dir: Path = PREPARED_DATASET_DIR,
) -> Dict[str, float]:
    """
    Evaluate a checkpoint on a dataset split.

    Args:
        cfg_path:        YAML / JSON used during training (to recreate model).
        checkpoint_path: Path to best model (.pt file).
        split:           Dataset split – "val" or "test".
        batch_size:      Optional override.

    Returns:
        Dict with metric names → values.
    """
    cfg = load_config(cfg_path)
    device = prepare_device(cfg.get("device"))
    debugging = cfg.get("debugging", False)
    padded: bool = model_to_padded[cfg["model"]["model_type"]]
    batch_size = cfg["data"].get("batch_size", 4)

    # --------------------------------------------------------------------- #
    # Model, optimiser, criterion                                           #
    # --------------------------------------------------------------------- #
    model_type = cfg["model"]["model_type"]
    model = get_model(model_type=model_type, **cfg["model"][model_type]).to(device)
    ckpt = torch.load(checkpoint_path, map_location=device)

    state = ckpt["model"] if isinstance(ckpt, dict) and "model" in ckpt else ckpt
    model.load_state_dict(state)
    logger.info(f"Loaded checkpoint from {checkpoint_path}")

    data_set = CdDataset(
        root_dir=preapred_dataset_dir,
        split=split,
        fit_scaler=False,
        padded=padded,
        debugging=debugging,
    )
    scaler = data_set.scaler
    unscale_fn = make_unscale(scaler=scaler)

    if padded:
        data_loader = DataLoader(
            data_set,
            batch_size=batch_size,
            pin_memory=(device.type == "cuda"),
            shuffle=False,
            drop_last=False,
        )
        evaluator = create_supervised_evaluator(
            model,
            metrics={
                "mae": MeanAbsoluteError(),
                "mse": MeanSquaredError(),
                "r2": R2Score(),
            },
            output_transform=unscale_fn,
            device=device,
        )
    else:
        data_loader = DataLoader(
            data_set,
            shuffle=True,
            drop_last=True,
            batch_size=batch_size,
            pin_memory=(device.type == "cuda"),
            collate_fn=ragged_collate_fn,
        )
        evaluator = create_supervised_evaluator(
            model,
            metrics={
                "mae": MeanAbsoluteError(),
                "mse": MeanSquaredError(),
                "r2": R2Score(),
            },
            output_transform=unscale_fn,
            prepare_batch=prepare_ragged_batch_fn,
            device=device,
        )

    eval_pbar = ProgressBar(desc=f"Evaluating ({split})", persist=True)
    eval_pbar.attach(evaluator)

    # run once
    evaluator.run(data_loader)
    metrics = evaluator.state.metrics
    metrics["rmse"] = metrics["mse"] ** 0.5
    logger.info(
        f"Split={split} | "
        f"MAE={metrics['mae']:.4f} MSE={metrics['mse']:.4f} "
        f"RMSE={metrics['rmse']:.4f} R2={metrics['r2']:.4f}"
    )

    return metrics

</file>

<file path="data/__init__.py">

</file>

<file path="data/dataset.py">
"""
CdDataset
~~~~~~~~~
Loads padded & masked 2-D slices from *.npz files, (optionally) normalises
the C_d StandardScaler, and returns tensors ready for
PyTorch-Ignite loops.

Normalisation rules
-------------------
* Fit the scaler **once** on the *train* split (all points where point_mask==1).
* Persist it to `constants.SCALER_FILE`.
* All other splits **load** the persisted scaler – never refit.
* Cd (target) is never scaled.
"""

from __future__ import annotations

from pathlib import Path

import numpy as np
import torch
from sklearn.preprocessing import StandardScaler
from torch.utils.data import Dataset
from torch_geometric.data import Batch, Data

from src.config.constants import SCALER_FILE
from src.utils.io import load_design_ids, load_scaler, save_scaler
from src.utils.logger import logger


def ragged_collate_fn(batch: list[tuple[np.ndarray, torch.Tensor]]):
    """
    Collate function for *non-padded* CdDataset samples.

    Each item in `batch` is:
        x = (slices_obj_array,)   # shape (num_slices,), slices_obj_array[i] -> (N_i, 2)
        y = Cd  (0-D tensor)

    Returns
    -------
    batched_slices : List[Batch]
        Length S list.  batched_slices[j] is a PyG Batch that contains
        all designs’ j-th slice stacked together (variable N_i handled by PyG).
        Each Data has attribute .x  →  (N_i, 2) float tensor.
    cd_values : torch.FloatTensor
        Shape (batch_size,)  target Cd for each car in the mini-batch.
    """
    # ----------------── unzip ----------------── #
    design_slices_list, cd_list = zip(*batch)
    # design_slices_list is a tuple of length batch_size. Each element in this tuple
    # is an object array of length num_slices.
    # cd_list is a tuple of length batch_size

    # ---------------- zip across slice index ---------------- #
    slices_by_index = zip(*design_slices_list)
    # generator of length num_slices
    # yields the list of slices at index i for all designs in the batch.

    batched_slices: list[Batch] = []
    for slice_list in slices_by_index:
        # len(slice_list) = batch_size.
        # Each element is (N_i, 2) ndarray
        data_list = [
            Data(x=torch.from_numpy(pts.astype(np.float32)))
            for pts in slice_list  # pts is a (N_i, 2) array
        ]
        batched_slices.append(Batch.from_data_list(data_list))

    cd_values = torch.stack(cd_list)  # shape -> (batch_size,)

    return batched_slices, cd_values


class CdDataset(Dataset):
    """
    Dataset yielding
    - if padded is True: (
                            x = (
                                    slices: shape -> (num_slices, target_points, 2),
                                    point_mask: shape -> (num_slices, target_points),
                                ),
                            y = Cd
                        )
    - if padded is False: (
                            x = slices: object array of
                                        shape -> (num_slices,), where each element
                                                 of the num_slices length array
                                                 is a 2D array of shape (N_i, 2)
                                                 where N_i is number of points
                                                 in the i_th slice.
                            y = Cd
                        )
    """

    def __init__(
        self,
        root_dir: Path,
        split: str,
        fit_scaler: bool = False,
        padded: bool = False,
        debugging: bool = False,
    ) -> None:
        """
        Initialize the dataset builder.

        Args:
            root_dir:   directory containing the *.npz files.
            split:      the data split to build dataset for.
            fit_scaler: if True, fit a new StandardScaler and persist it,
                        otherwise load the persisted scaler.
                        We fit on the training split, and use that for validation
                        and testing split.
            padded:     if True, the .npz files have point_mask and padded slices.
                        Otherwise the .npz files have raw slices and Cd only.
        """
        self.padded = padded
        self.root_dir = Path(root_dir)
        design_ids = load_design_ids(split)
        all_npz_file_paths = self.root_dir.glob("*.npz")
        self.file_paths = sorted(f for f in all_npz_file_paths if f.stem in design_ids)
        if debugging:
            self.file_paths = self.file_paths[:200]
        if not self.file_paths:
            raise RuntimeError(f"No data found in {self.root_dir}")

        # ----------------------------------------------------------------- #
        # Build / load Cd-scaler                                            #
        # ----------------------------------------------------------------- #
        self.scaler: StandardScaler
        try:
            self.scaler = (
                self._fit_and_save_scaler() if fit_scaler else load_scaler(SCALER_FILE)
            )
            if self.scaler.mean_ is None or self.scaler.scale_ is None:
                raise ValueError(
                    "Transformation Scaler not loaded correctly. Can't get the"
                    " mean and scale."
                )
        except Exception as e:
            logger.error(f"Error in getting transformation scaler. Error msg: {e}")
            raise e

        logger.info(
            f"{split:<5} dataset with {len(self.file_paths)} samples | "
            f"Cd Scaler mean={self.scaler.mean_[0]:.3f} | "
            f"Cd Scaler scale={self.scaler.scale_[0]:.3f}"
        )

    # ------------------------------ scaler ------------------------------ #
    def _fit_and_save_scaler(self) -> StandardScaler:
        """
        Fit a StandardScaler on Cd values from the split.
        """
        logger.info("Fitting StadnardScaler on Cd targets")
        cds = np.array(
            [self._load_npz(fp, only_cd=True, scale=False) for fp in self.file_paths],
            dtype=np.float32,
        ).reshape(-1, 1)
        scaler = StandardScaler().fit(cds)
        save_scaler(scaler, SCALER_FILE)
        logger.info(f"Scaler saved -> {SCALER_FILE}")
        return scaler

    # ---------------------------- I/O utils ----------------------------- #
    def _load_npz(self, fp: Path, *, only_cd: bool = False, scale: bool = True):
        """
        Load the required data from the .npz file stored at `fp`.

        Args:
            fp: Path to the npz file.
            only_cd: if True, return only the Cd value.
            scale: if True, scale the Cd before returning.

        Returns:
        - if only_cd is False: Returns a tuple
            - if padded is True: (slices, point_mask, cd)
                - slices: shape -> (num_slices, target_points, 2)
                - point_mask: shape -> (num_slices, target_points)
            - if padded is False: (slices, cd)
                - slices: shape -> (numb_slices,)
        - if only_cd is True: Cd value (float)
        """
        data = np.load(fp, allow_pickle=True)
        cd = data["Cd"]
        if scale:
            cd = float(self.scaler.transform([[cd]])[0, 0])
        if only_cd:
            return cd
        slices = data["slices"]
        if self.padded:
            point_mask = data["point_mask"]
            return slices.astype(np.float32), point_mask.astype(np.float32), cd
        else:
            return slices, cd

    # ------------------------- standard Dataset ------------------------- #
    def __len__(self) -> int:
        return len(self.file_paths)

    def __getitem__(self, idx: int):
        """
        Returns:
            x:
                • if padded=True: a 2-tuple
                    (slices: FloatTensor of shape (num_slices, target_points, 2),
                    point_mask: FloatTensor of shape (num_slices, target_points))
                • if padded=False:
                    slices_obj: a NumPy object-dtype array of length num_slices,
                                where slices_obj[i] has shape (Ni, 2)

            y:
                A 0-D FloatTensor containing the Cd value.
        """
        if self.padded:
            slices, point_mask, cd = self._load_npz(self.file_paths[idx])
            x = (
                torch.from_numpy(slices),
                torch.from_numpy(point_mask),
            )
        else:
            slices, cd = self._load_npz(self.file_paths[idx])
            x = slices
        y = torch.tensor(cd, dtype=torch.float32)
        return x, y

</file>

<file path="data/slices.py">
"""
Loads .paddle_tensor point clouds, bins them into num_slices along axis.
Pads the slices to target number of points per slice.
"""

from pathlib import Path
from typing import Literal, Optional, Sequence

import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
from tqdm.contrib.logging import logging_redirect_tqdm

from src.config.constants import (
    DEFAULT_SLICE_AXIS,
    DEFAULT_TARGET_POINTS,
    SUBSET_DIR,
)
from src.utils.io import load_cd_map, load_design_ids, load_point_cloud
from src.utils.logger import logger


class PointCloudSlicer:
    def __init__(
        self,
        input_dir: Path,
        output_dir: Path,
        num_slices: int,
        axis: str,
        max_files: Optional[int],
        split: Literal["train", "val", "test", "all", "predict"],
        subset_dir: Path,
    ) -> None:
        """
        Args:
            input_dir: Path to the directory with the Point Clouds (.paddle_tensor files)
            output_dir: Path to the directory where the slices (.npy files) will be saved.
            num_slices: Number of slices to divide the point clouds into.
            axis: Axis along which to slice the point clouds. Must be one of 'x', 'y', or 'z'.
            max_files: Maximum number of files to process. If None, process all files.
            split: The data split to slice.
            subset_dir: Path to the directory with the design IDs for the split. (.txt files)
        """
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.num_slices = num_slices
        self.axis = axis
        self.max_files = max_files
        self.split = split
        self.subset_dir = Path(subset_dir)

        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.axis_map = {"x": 0, "y": 1, "z": 2}
        if self.axis not in self.axis_map:
            raise ValueError("Axis must be one of 'x', 'y', or 'z'.")

        if self.split == "all":
            self.valid_ids = (
                load_design_ids("train", self.subset_dir)
                | load_design_ids("val", self.subset_dir)
                | load_design_ids("test", self.subset_dir)
            )
        elif self.split != "predict":
            self.valid_ids = load_design_ids(self.split, self.subset_dir)

    def generate_slices(self, points: np.ndarray) -> list[np.ndarray]:
        """
        Divides the point clouds along the axis `self.axis` into `self.num_slices` bins
        and returns the slices.

        Args:
            points: A numpy ndarray of shape (N,3) where N is the number of points
            in the point cloud.
        Returns:
            A list of length `self.num_slices` where each element is a 2-column array
            of shape (N_i, 2), where N_i is the number of points in the i_th slice.
        """
        axis = self.axis_map[self.axis]
        coords_along_axis = points[:, axis]
        min_val, max_val = coords_along_axis.min(), coords_along_axis.max()
        bin_edges = np.linspace(min_val, max_val, self.num_slices + 1)

        slices = []
        for i in range(self.num_slices):
            low, high = bin_edges[i], bin_edges[i + 1]
            # create a boolean mask to identify the pionts that will fall in this bin
            mask = (coords_along_axis >= low) & (coords_along_axis < high)
            # get all the points that fall in this bin
            slice_points = points[mask]

            # drop the coordinates along `self.axis` to project all the points in this bin
            # to the plane perpendicular to `self.axis`. This is one slice.
            slice = np.delete(slice_points, axis, axis=1)
            slices.append(slice)

        return slices

    def process_file(self, file_path: Path) -> list[np.ndarray]:
        """
        Slice the point cloud and return the slices.

        Args:
            file_path: Path to the .paddle_tensor file.
        Returns:
            The list of slices for this point cloud.
        """
        points = load_point_cloud(file_path)
        slices = self.generate_slices(points)
        total_points = sum(len(sl) for sl in slices)
        logger.info(
            f"{file_path.name} -> {total_points} total points across {len(slices)} slices."
        )
        return slices

    def run(self):
        """
        Slice all the point clouds in the `self.input_dir` correspondings to the
        design IDs for `self.split` and save the slices (.npy file) to `self.output_dir` for each.
        """
        all_files = sorted(self.input_dir.glob("*.paddle_tensor"))
        filtered_files = [f for f in all_files if f.stem in self.valid_ids]

        if self.max_files is not None:
            filtered_files = filtered_files[: self.max_files]

        logger.info(
            f"Processing {len(filtered_files)} point clouds from split: {self.split}"
        )

        count_success, count_error = 0, 0

        with logging_redirect_tqdm():
            for file_path in tqdm(filtered_files, desc=f"Slicing {self.split} set"):
                try:
                    design_id = file_path.stem
                    output_path = self.output_dir / f"{design_id}_axis-{self.axis}.npy"
                    slices = self.process_file(file_path)
                    np.save(
                        output_path, np.array(slices, dtype=object), allow_pickle=True
                    )
                    count_success += 1
                except Exception as e:
                    logger.error(f"Error processing {file_path}: {str(e)}")
                    count_error += 1

        logger.info(
            f"Finished slicing split '{self.split}': {count_success} succeeded, {count_error} failed."
        )


def pad_and_mask_slices(
    slices: Sequence[np.ndarray],
    target_points=DEFAULT_TARGET_POINTS,
) -> tuple[np.ndarray, np.ndarray]:
    """
    Pad the slices to have a fixed (`target_points`) number of points per slice.

    Args:
        slices: A sequence of slices, each a 2-column array of shape (N, 2).
        target_points: The target number of points per slice.

    Returns:
        A tuple of two elements:
        - padded: float32 ndarray of shape (num_slices, target_points, 2)
        - point_mask: float32 ndarray of shape (num_slices, target_points).
    """
    num_slices = len(slices)
    padded = np.zeros((num_slices, target_points, 2), dtype=np.float32)
    point_mask = np.zeros((num_slices, target_points), dtype=np.float32)

    for i, sl in enumerate(slices):
        # expected shape of a slice: (N_i, 2)
        if sl.shape[0] == 0:
            continue
        if target_points < sl.shape[0]:
            raise ValueError(
                f"Number of points in a slice is greater than {target_points}"
            )
        n_pts = sl.shape[0]
        padded[i, :n_pts] = sl[:n_pts]
        point_mask[i, :n_pts] = 1

    return padded, point_mask


def prepare_dataset(
    slice_dir: Path,
    output_dir: Path,
    split: Literal["train", "val", "test", "all"],
    target_points: Optional[int] = None,
    subset_dir=SUBSET_DIR,
) -> None:
    """
    Prepare the dataset (.npz files) and save them to output_dir or
    output_dir/padded if target_points is provided.
    The .npz files saved have the Cd zipped together with the slices
    (and optionally point mask if `target_points` is provided).

    Args:
        slice_dir: Path to the directory with the slices (.npy files)
        output_dir: Path to the directory where the prepared dataset (.npz files) will be saved.
        split: The data split to prepare.
        target_points: The target number of points per slice if padding is required.
        subset_dir: Path to the directory with the design IDs for the split. (.txt files)

    """
    slice_dir = Path(slice_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    if split == "all":
        design_ids = (
            load_design_ids("train", subset_dir)
            | load_design_ids("val", subset_dir)
            | load_design_ids("test", subset_dir)
        )
    else:
        design_ids = load_design_ids(split, subset_dir)
    cd_map = load_cd_map()
    logger.info(f"Preparing split: {split} -> {len(design_ids)} design IDs")

    all_files = [f for f in slice_dir.glob("*.npy")]
    matched = [f for f in all_files if f.stem.split("_axis")[0] in design_ids]
    logger.info(f"Matched {len(matched)} files in {slice_dir} for split '{split}'")

    with logging_redirect_tqdm():
        for fname in tqdm(
            matched,
            desc=f"Prepare Dataset for split {split}, padded={True if target_points else False}",
        ):
            in_path = fname
            try:
                slices = np.load(in_path, allow_pickle=True)

                processed_slices, point_mask = None, None

                if target_points:
                    pad_dir = output_dir / "padded"
                    pad_dir.mkdir(parents=True, exist_ok=True)

                    # pad the slices if `target_points` is provided.
                    # This is needed for backwards compatibility with LSTM model.
                    processed_slices, point_mask = pad_and_mask_slices(
                        slices, target_points
                    )
                    save_dir = pad_dir
                else:
                    processed_slices = slices
                    save_dir = output_dir

                design_id = fname.stem
                design_id = design_id.split("_axis")[0]
                cd_val = cd_map.get(design_id)
                if cd_val is None:
                    logger.warning(f"Cd not found for {design_id} – file skipped")
                    continue

                out_path = save_dir / f"{design_id}.npz"
                if target_points:
                    np.savez_compressed(
                        out_path,
                        slices=processed_slices,
                        point_mask=point_mask,
                        Cd=cd_val,
                    )
                else:
                    np.savez_compressed(
                        out_path,
                        slices=processed_slices,
                        Cd=cd_val,
                    )
            except Exception as e:
                logger.warning(
                    f"Preparing dataset for design_id: {fname.name} failed: {e}"
                )

    logger.info(f"Done: Saved {len(matched)} data points to {output_dir}")


def display_slices(
    slices,
    design_id=None,
    n_cols=5,
    limit=None,
    figsize=(15, 3),
    axis=DEFAULT_SLICE_AXIS,
    save_path=None,
):
    """
    Display or save 2D slices from a point cloud.

    slices: list of (num_of_points, 2) np arrays
    """
    if limit:
        slices = slices[:limit]

    all_points = np.vstack([sl for sl in slices if sl.size])
    xmin, xmax = all_points[:, 0].min(), all_points[:, 0].max()
    ymin, ymax = all_points[:, 1].min(), all_points[:, 1].max()

    pad_x = 0.02 * (xmax - xmin)
    pad_y = 0.02 * (ymax - ymin)
    xmin, xmax = xmin - pad_x, xmax + pad_x
    ymin, ymax = ymin - pad_y, ymax + pad_y

    n = len(slices)
    n_rows = int(np.ceil(n / n_cols))
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(figsize[0], figsize[1] * n_rows))

    for idx, sl in enumerate(slices):
        ax = axes.flat[idx]
        if sl.size:
            ax.scatter(sl[:, 0], sl[:, 1], s=2, c="k")
        else:
            ax.text(0.5, 0.5, "Empty", ha="center", va="center")
        ax.set_xlim(xmin, xmax)
        ax.set_ylim(ymin, ymax)
        ax.set_aspect("equal", adjustable="box")
        ax.axis("off")
        ax.set_title(f"{axis} ∈ slice {idx}", fontsize=8)

    for j in range(n, n_rows * n_cols):
        axes.flat[j].axis("off")

    fig.suptitle(
        f"Slices for {design_id}" if design_id else "Point Cloud Slices", fontsize=14
    )
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300)
        print(f"[✓] Saved to {save_path}")
        plt.close()
    else:
        plt.show()

</file>

